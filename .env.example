# ============================================
# Smart RAG Configuration
# ============================================
# Copy this file to .env and fill in your values
# Do NOT commit .env to version control

# ============================================
# Application Settings
# ============================================
APP_NAME=Smart RAG
APP_VERSION=0.1.0
APP_DEBUG=false
LOG_LEVEL=INFO

# ============================================
# OpenAI Configuration
# ============================================
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key-here

# Model Selection
OPENAI_MODEL=gpt-4-turbo-preview
OPENAI_EMBEDDING_MODEL=text-embedding-3-large

# Model Parameters
OPENAI_TEMPERATURE=0.5
OPENAI_MAX_TOKENS=2000

# ============================================
# Neo4j Database Configuration
# ============================================
# For Docker deployment (default)
NEO4J_URI=bolt://neo4j:7687
# For local deployment, use:
# NEO4J_URI=bolt://localhost:7687

NEO4J_USER=neo4j
# IMPORTANT: Change this to a secure password
NEO4J_PASSWORD=change-this-secure-password
NEO4J_DATABASE=neo4j

# ============================================
# Document Processing Settings
# ============================================
# Size of text chunks (in characters)
CHUNK_SIZE=1000

# Overlap between chunks (in characters)
CHUNK_OVERLAP=200

# Maximum number of entities to extract per chunk
MAX_ENTITIES_PER_CHUNK=50

# Number of chunks to process in a single embedding API call (higher = faster, more memory)
EMBEDDING_BATCH_SIZE=20

# ============================================
# Graph Construction Settings
# ============================================
# Minimum number of nodes in a community
MIN_COMMUNITY_SIZE=3

# Maximum levels in the hierarchical graph
MAX_HIERARCHY_LEVELS=3

# Similarity threshold for entity/chunk relationships (0.0-1.0)
SIMILARITY_THRESHOLD=0.7

# ============================================
# RAG (Retrieval-Augmented Generation) Settings
# ============================================
# Number of chunks to retrieve for a query
TOP_K_RETRIEVAL=10

# Number of top chunks after reranking
RERANK_TOP_K=5

# Maximum context length to send to LLM (in characters)
MAX_CONTEXT_LENGTH=8000

# Minimum similarity threshold for retrieval (0.0 = accept all results, let LLM decide relevance)
# Set higher (e.g., 0.5-0.7) if you want to pre-filter low-similarity chunks
MIN_SIMILARITY_THRESHOLD=0

# Minimum similarity threshold for retrieval (0.0-1.0)
# Lower values = more lenient (retrieve more results)
# Higher values = stricter (only highly similar results)
# Recommended: 0.5 for general use, 0.6-0.7 for high precision
MIN_SIMILARITY_THRESHOLD=0.5

# ============================================
# Advanced Retrieval Settings
# ============================================
# Enable HNSW vector index for faster similarity search (requires Neo4j 5.11+)
USE_HNSW_INDEX=true

# HNSW index parameters
HNSW_M=16
HNSW_EF_CONSTRUCTION=200
HNSW_EF_SEARCH=100

# Enable hybrid search (BM25 + vector similarity)
ENABLE_HYBRID_SEARCH=true
BM25_WEIGHT=0.3
VECTOR_WEIGHT=0.7

# Enable entity-aware expansion
ENABLE_ENTITY_EXPANSION=true
ENTITY_EXPANSION_HOPS=2

# Enable cross-encoder reranking (UPGRADED TO BETTER MODEL)
ENABLE_RERANKING=true
RERANKER_MODEL=BAAI/bge-reranker-large

# Enable query decomposition for complex queries
ENABLE_QUERY_DECOMPOSITION=true
MAX_SUBQUERIES=3

# ============================================
# Semantic Chunking Settings
# ============================================
# Use semantic chunking instead of fixed-size chunking
USE_SEMANTIC_CHUNKING=true
SEMANTIC_THRESHOLD=0.5
MIN_CHUNK_SIZE=200
MAX_CHUNK_SIZE=2000

# ============================================
# Entity Disambiguation Settings
# ============================================
# Enable entity disambiguation and coreference resolution
ENABLE_ENTITY_DISAMBIGUATION=true
DISAMBIGUATION_THRESHOLD=0.8

# ============================================
# Feedback and Learning Settings
# ============================================
# Enable relevance feedback loop
ENABLE_FEEDBACK_LOOP=true
FEEDBACK_LEARNING_RATE=0.1

# ============================================
# Caching Settings (New)
# ============================================
# Redis URL for caching (optional - will use in-memory cache if not set)
# Format: redis://host:port or redis://username:password@host:port
# Leave empty to use in-memory LRU cache as fallback
REDIS_URL=

# Cache TTL in seconds (default 3600 = 1 hour)
CACHE_TTL=3600

# Enable query result caching (5min TTL)
ENABLE_QUERY_CACHE=true

# Enable embedding caching (24hr TTL) - saves API costs
ENABLE_EMBEDDING_CACHE=true

# ============================================
# Advanced RAG Features (New)
# ============================================
# Enable HyDE (Hypothetical Document Embeddings) for better retrieval
ENABLE_HYDE=true

# Enable query reformulation for better coverage
ENABLE_QUERY_REFORMULATION=true

# Enable context compression for efficiency
ENABLE_CONTEXT_COMPRESSION=true

# Context compression ratio (0.0-1.0, default 0.6 = 60% of original)
CONTEXT_COMPRESSION_RATIO=0.6

# Enable streaming responses
ENABLE_STREAMING=true

# ============================================
# Ultra-Advanced Accuracy Features (NEW)
# ============================================
# Self-consistency: Generate multiple answers and select most consistent
ENABLE_SELF_CONSISTENCY=true
SELF_CONSISTENCY_SAMPLES=3

# Answer confidence scoring: Detect when to say "I don't know"
ENABLE_ANSWER_CONFIDENCE=true
MIN_CONFIDENCE_THRESHOLD=0.5

# Temporal-aware ranking: Prioritize recent or historical information
ENABLE_TEMPORAL_RANKING=true
TEMPORAL_DECAY_FACTOR=0.95

# Citation extraction: Extract exact quotes from sources
ENABLE_CITATION_EXTRACTION=true
MAX_CITATION_LENGTH=200

# Factuality verification: Detect hallucinations and unverified claims
ENABLE_FACTUALITY_VERIFICATION=true

# Conflict resolution: Handle contradictory sources
ENABLE_CONFLICT_RESOLUTION=true

# Query intent classification: Better understand query type
ENABLE_QUERY_INTENT_CLASSIFICATION=true

# Iterative refinement: Improve answers through multiple passes
ENABLE_ITERATIVE_REFINEMENT=true
MAX_REFINEMENT_ITERATIONS=2

# Active learning: Learn from user feedback
ENABLE_ACTIVE_LEARNING=true
LEARNING_RATE=0.01
